# ü§ñ Clasificador de Algoritmos con ML

Este m√≥dulo entrena un modelo de Machine Learning para clasificar autom√°ticamente pseudoc√≥digos por tipo de algoritmo.

## üìã Flujo completo

```
1. Generar Dataset (con Claude) ‚Üí generar_dataset.py
2. Entrenar Clasificador (offline) ‚Üí entrenar_clasificador.py  
3. Usar en Producci√≥n (r√°pido, sin LLM) ‚Üí clasificador.py
```

## üèóÔ∏è Paso 1: Generar Dataset

**Archivo:** `generar_dataset.py`

Usa Claude (LLM) para generar ejemplos sint√©ticos de pseudoc√≥digos.

### Categor√≠as definidas:
- **B√∫squeda**: lineal, binaria, hash (45 ejemplos)
- **Ordenamiento**: bubble, selection, insertion, merge, quick, heap (90 ejemplos)
- **Recursivo D&C**: fibonacci, factorial, torres hanoi, multiplicaci√≥n (48 ejemplos)
- **Iterativo**: suma array, m√°ximo/m√≠nimo, conteo (48 ejemplos)
- **Programaci√≥n Din√°mica**: fibonacci_dp, mochila, LCS (30 ejemplos)
- **Greedy**: cambio monedas, mochila fraccionaria (30 ejemplos)
- **Grafos**: BFS, DFS, Dijkstra, Prim (40 ejemplos)

**Total estimado: ~330 ejemplos**

### Ejecutar:
```bash
cd Backend/ml
python generar_dataset.py
```

**Salida:** 
- `dataset/dataset_completo.json` - Todos los ejemplos
- `dataset/dataset_<categoria>.json` - Por categor√≠a

**Formato JSON:**
```json
{
  "id": "busqueda_binaria_1",
  "categoria": "busqueda",
  "subcategoria": "binaria",
  "pseudocodigo": "funcion busqueda_binaria(arr, x)...",
  "label": "busqueda"
}
```

## üéì Paso 2: Entrenar Clasificador

**Archivo:** `entrenar_clasificador.py`

Entrena un clasificador SVM con vectorizaci√≥n TF-IDF.

### Caracter√≠sticas:
- **Vectorizaci√≥n**: TF-IDF con n-gramas (1-3)
- **Modelo**: SVM con kernel RBF
- **Sin GPU**: Funciona en cualquier m√°quina
- **R√°pido**: Entrenamiento en minutos

### Ejecutar:
```bash
cd Backend/ml
python entrenar_clasificador.py
```

**Salida:**
- `modelos/clasificador_vectorizer.pkl` - Vectorizador TF-IDF
- `modelos/clasificador_encoder.pkl` - Codificador de etiquetas
- `modelos/clasificador_modelo.pkl` - Modelo SVM entrenado

**M√©tricas esperadas:**
- Accuracy: 85-95% (dependiendo del dataset)
- Precision/Recall por categor√≠a
- Matriz de confusi√≥n

## üöÄ Paso 3: Usar en Producci√≥n

**Archivo:** `clasificador.py`

Carga el modelo y clasifica pseudoc√≥digos **instant√°neamente** (sin LLM).

### Ejemplo de uso:

```python
from ml.clasificador import obtener_clasificador

# Cargar clasificador (una sola vez)
clasificador = obtener_clasificador()

# Clasificar
pseudocodigo = """
funcion busqueda_binaria(arr, target):
    izq = 0
    der = longitud(arr) - 1
    mientras izq <= der:
        medio = (izq + der) / 2
        si arr[medio] == target:
            retornar medio
        sino si arr[medio] < target:
            izq = medio + 1
        sino:
            der = medio - 1
    retornar -1
"""

resultado = clasificador.clasificar(pseudocodigo)

print(resultado)
# {
#   'categoria_principal': 'busqueda',
#   'confianza': 0.92,
#   'top_predicciones': [
#     {'categoria': 'busqueda', 'probabilidad': 0.92},
#     {'categoria': 'iterativo', 'probabilidad': 0.05},
#     {'categoria': 'recursivo_divide_conquista', 'probabilidad': 0.03}
#   ]
# }
```

### Test r√°pido:
```bash
cd Backend/ml
python clasificador.py
```

## üîó Integraci√≥n con FlujoAnalisis

Modificar `Backend/flujo_analisis.py` para usar el clasificador como primer paso:

```python
from ml.clasificador import obtener_clasificador

clasificador = obtener_clasificador()

def analizar_algoritmo(pseudocodigo: str):
    # 1. CLASIFICAR (nuevo paso)
    clasificacion = clasificador.clasificar(pseudocodigo)
    print(f"Tipo detectado: {clasificacion['categoria_principal']}")
    
    # 2. Traducir (existente)
    traduccion = traductor.traducir(pseudocodigo)
    
    # 3. Validar (existente)
    # ...
    
    # 4. Detectar complejidad (existente)
    # ...
```

## üìä Ventajas del enfoque

‚úÖ **Sin LLM en producci√≥n**: Clasificaci√≥n instant√°nea (<100ms)  
‚úÖ **Bajo costo**: Solo se usa Claude para generar dataset (una vez)  
‚úÖ **Sin GPU**: Funciona en cualquier servidor  
‚úÖ **Explainable**: TF-IDF permite ver qu√© palabras influyeron  
‚úÖ **Actualizable**: Regenerar dataset y reentrenar cuando sea necesario  

## üõ†Ô∏è Dependencias

```bash
pip install scikit-learn numpy
```

O:
```bash
pip install -r requirements_ml.txt
```

## üìù Notas

- El dataset se genera UNA VEZ con Claude
- El modelo se entrena OFFLINE
- En producci√≥n NO se usa LLM (r√°pido y barato)
- Si necesitas m√°s ejemplos, ajusta `ejemplos_por_sub` en `generar_dataset.py`
- Si el accuracy es bajo, genera m√°s ejemplos o ajusta hiperpar√°metros en `entrenar_clasificador.py`
